{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-iris-data-norm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmarches/CNN-Example-Google-Colaboratory/blob/master/keras_iris_data_norm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toMAcYCGF8Ec",
        "colab_type": "code",
        "outputId": "1bf8b4e8-d817-4120-b456-bb552d16c761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "'''Using covertype dataset from kaggle to predict forest cover type'''\n",
        "#Import pandas, tensorflow and keras\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "y = iris['target']\n",
        "names = iris['target_names']\n",
        "feature_names = iris['feature_names']\n",
        "\n",
        "\n",
        "# One hot encoding\n",
        "enc = OneHotEncoder()\n",
        "Y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
        "\n",
        "# Scale data to have mean 0 and variance 1 \n",
        "# which is importance for convergence of the neural network\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data set into training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X_scaled, Y, test_size=0.5, random_state=2)\n",
        "\n",
        "n_features = X.shape[1]\n",
        "n_classes = Y.shape[1]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhM3nInKG3_c",
        "colab_type": "text"
      },
      "source": [
        "https://janakiev.com/notebooks/keras-iris/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIkjUYvIF9M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split data into train and test \n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.7, random_state =  90)\n",
        "'''As y variable is multi class categorical variable, hence using softmax as activation function and sparse-categorical cross entropy as loss function.'''\n",
        "model = keras.Sequential([\n",
        " keras.layers.Dense(64, activation=tf.nn.relu,                  \n",
        " input_shape=(x_train.shape[1],)),\n",
        " keras.layers.Dense(64, activation=tf.nn.relu),\n",
        " keras.layers.Dense(8, activation=  'softmax')\n",
        " ])\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history1 = model.fit(\n",
        " x_train, y_train,\n",
        " epochs= 26, batch_size = 60,\n",
        " validation_data = (x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}